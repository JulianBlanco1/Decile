{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9657945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import whisper, torch\n",
    "from pathlib import Path\n",
    "import jiwer\n",
    "from jiwer import *\n",
    "import csv\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371d0b3",
   "metadata": {},
   "source": [
    "Normalizar los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1540fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveDiacritics:\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, str):\n",
    "            # Normaliza a NFD y elimina los caracteres de acento (categoria Mn)\n",
    "            return \"\".join(\n",
    "                c for c in unicodedata.normalize(\"NFD\", x)\n",
    "                if unicodedata.category(c) != \"Mn\"\n",
    "            )\n",
    "        elif isinstance(x, list):\n",
    "            # Procesar recursivamente cada elemento\n",
    "            return [self.__call__(s) for s in x]\n",
    "        else:\n",
    "            return x\n",
    "tr_w = jiwer.Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),   \n",
    "    RemoveDiacritics(),           \n",
    "    RemovePunctuation(),               \n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "    ReduceToListOfListOfWords(),\n",
    "])\n",
    "\n",
    "tr_c = jiwer.Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),\n",
    "    RemoveDiacritics(),\n",
    "    RemovePunctuation(),\n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "    ReduceToListOfListOfChars(),\n",
    "])\n",
    "\n",
    "tr= jiwer.Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),   \n",
    "    RemoveDiacritics(),           \n",
    "    RemovePunctuation(),               \n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580acc7",
   "metadata": {},
   "source": [
    "Cálculo de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8d3016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(refs:str, hyps: str):\n",
    "    #DADA UNA REFERENCIA (transcripción real) Y UNA HIPÓTESIS (output transcripto por el modelo) para un cierto MODELO, devuelve un diccionario de métricas asociadas a ese audio y transcripción\n",
    "    metricas = dict()\n",
    "\n",
    "    # Word Error Rate\n",
    "    out_wer = jiwer.process_words(refs, hyps, reference_transform=tr_w, hypothesis_transform=tr_w)\n",
    "    # Character Error Rate\n",
    "    out_cer = jiwer.process_characters(refs, hyps, reference_transform=tr_c, hypothesis_transform=tr_c)\n",
    "\n",
    "    metricas[\"WER\"] = out_wer.wer\n",
    "    metricas[\"CER\"] = out_cer.cer\n",
    "    metricas[\"ALINEACION\"] = jiwer.visualize_alignment(out_wer)\n",
    "    metricas[\"ERRORES\"] = jiwer.visualize_error_counts(out_wer)\n",
    "\n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d0344",
   "metadata": {},
   "source": [
    "Cálculo del promedio de las métricas a partir de un diccionario con todos nuestros resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03c41fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_promedio(models_data:dict[dict[dict[str:str]]]):\n",
    "    #DEVUELVE: un diccionario donde las claves son los modelos y el valor es el WER promedio asociado a ese modelo\n",
    "    promediosWER = dict()\n",
    "    promediosCER = dict()\n",
    "    for modelo in models_data.keys():\n",
    "        sumaWER = 0\n",
    "        sumaCER = 0\n",
    "        for registro in models_data[modelo].keys():\n",
    "                sumaWER += models_data[modelo][registro][\"METRICS\"][\"WER\"]\n",
    "                sumaCER += models_data[modelo][registro][\"METRICS\"][\"CER\"]\n",
    "        promedioWER = sumaWER/len(models_data[modelo])\n",
    "        promedioCER = sumaCER/len(models_data[modelo])\n",
    "        promediosWER[modelo] = promedioWER\n",
    "        promediosCER[modelo] = promedioCER\n",
    "        \n",
    "    return promediosWER, promediosCER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec5237",
   "metadata": {},
   "source": [
    "Confección del diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a330362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_archivo:str, modelo:str, models_data):\n",
    "    print(\"MODELO: \", modelo)\n",
    "\n",
    "    if modelo not in models_data:\n",
    "        models_data[modelo] = {}\n",
    "\n",
    "    model = whisper.load_model(modelo)\n",
    "\n",
    "    with open(data_archivo, encoding=\"utf-8\") as f:\n",
    "        r = csv.DictReader(f, delimiter=\",\")\n",
    "        for registro in r: \n",
    "            audio = registro['AUDIO']\n",
    "            ref = registro[\"TRANSCRIPCION\"]\n",
    "\n",
    "            hyp = model.transcribe(audio, language=\"es\", fp16=False)[\"text\"]\n",
    "\n",
    "            metricas = calcular_metricas(ref, hyp)\n",
    "            \n",
    "            audio_key = Path(audio).stem    \n",
    "            print(audio_key)\n",
    "        \n",
    "            models_data[modelo][audio_key] = dict()\n",
    "            models_data[modelo][audio_key][\"REF\"] = ref\n",
    "            models_data[modelo][audio_key][\"HYP\"] = hyp\n",
    "            models_data[modelo][audio_key][\"METRICS\"] = dict()\n",
    "            models_data[modelo][audio_key][\"METRICS\"][\"WER\"] = metricas[\"WER\"]\n",
    "            models_data[modelo][audio_key][\"METRICS\"][\"CER\"] = metricas[\"CER\"]\n",
    "            models_data[modelo][audio_key][\"METRICS\"][\"ALINEACION\"] = metricas[\"ALINEACION\"]\n",
    "            models_data[modelo][audio_key][\"METRICS\"][\"ERRORES\"] = metricas[\"ERRORES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81bce55",
   "metadata": {},
   "source": [
    "Función para visualizar el diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c88e75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printear_models_data(models_data: dict[dict[dict[str:str]]]):\n",
    "    print(\"\\nRESULTADOS: \\n\")\n",
    "    for modelo, registros in models_data.items():\n",
    "        print(f\"MODELO: {modelo}\\n\")\n",
    "        for registro, info in registros.items():\n",
    "            print(f\"    {registro}\")\n",
    "            print(\"         REF:\")\n",
    "            print(f\"             {info['REF']}\")\n",
    "            print(\"         HYP:\")\n",
    "            print(f\"            {info['HYP']}\")\n",
    "\n",
    "            m = info[\"METRICS\"]\n",
    "            print(\"         MÉTRICAS:\")\n",
    "            print(f\"            - WER: {m['WER']:.3f}\")\n",
    "            print(f\"            - CER: {m['CER']:.3f}\")\n",
    "            print(\"            - ALINEACIÓN (palabras):\")\n",
    "            print(m[\"ALINEACION\"])\n",
    "            print(\"            - ERRORES (resumen):\")\n",
    "            print(m[\"ERRORES\"])\n",
    "            print(\"\\n\")\n",
    "        print(\"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217de316",
   "metadata": {},
   "source": [
    "Graficos de las métricas promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccdabbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_incremental(\n",
    "    metrica:str,\n",
    "    models_data,\n",
    "    model_order=None,\n",
    "    sort_audios=\"alphabetical\",\n",
    "    figsize=(12, 5),\n",
    "    save_prefix=\"wers_step\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Grafica WER por audio de manera incremental:\n",
    "    - Primer gráfico: solo el primer modelo\n",
    "    - Segundo: primer modelo + segundo modelo\n",
    "    - etc.\n",
    "    \"\"\"\n",
    "\n",
    "    # audios: union de todos los keys\n",
    "    audios = sorted({a for registros in models_data.values() for a in registros.keys()})\n",
    "\n",
    "    # usar orden alfabético de modelos si no se pasa order explícito\n",
    "    if model_order is None:\n",
    "        model_order = sorted(models_data.keys())\n",
    "\n",
    "    # preparar datos\n",
    "    wers_by_model = {}\n",
    "    for m in model_order:\n",
    "        wers_by_model[m] = [\n",
    "            models_data[m][a][\"METRICS\"][metrica] if a in models_data[m] else None\n",
    "            for a in audios\n",
    "        ]\n",
    "\n",
    "    saved_paths = []\n",
    "    for k in range(1, len(model_order) + 1):\n",
    "        plt.figure(figsize=figsize)\n",
    "        x = list(range(len(audios)))\n",
    "        for m in model_order[:k]:\n",
    "            y = [\n",
    "                float(\"nan\") if v is None else v\n",
    "                for v in wers_by_model[m]\n",
    "            ]\n",
    "            plt.scatter(x, y, label=m)\n",
    "        etiquetas = [a[:6] + a[9] for a in audios]\n",
    "        plt.xticks(x, etiquetas, rotation=90)\n",
    "        plt.xlabel(\"Audio\")\n",
    "        plt.ylabel(metrica)\n",
    "        plt.title(f\"{metrica} por audio — modelos: {', '.join(model_order[:k])}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        path = f\"{save_prefix}_{metrica.lower()}_{k}.png\"\n",
    "        plt.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
    "        saved_paths.append(path)\n",
    "        plt.close()  # no abrir ventana en scripts\n",
    "\n",
    "\n",
    "    return saved_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654ec446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots_metric(models_data: dict,\n",
    "                         metric: str,\n",
    "                         model_order=None,\n",
    "                         figsize=(10, 5),\n",
    "                         save_path=None,\n",
    "                         show=False):\n",
    "    \"\"\"\n",
    "    Dibuja un gráfico con N boxplots (uno por modelo) para la métrica indicada.\n",
    "      - metric: \"WER\" o \"CER\" (insensible a mayúsculas)\n",
    "      - model_order: lista explícita con el orden de modelos (si None, usa orden alfabético)\n",
    "      - figsize: tamaño de la figura en pulgadas\n",
    "      - save_path: ruta del PNG a guardar (si None, genera un nombre a partir de la métrica)\n",
    "      - show: si True, llama a plt.show() (útil en entornos con GUI)\n",
    "    Devuelve la ruta del archivo guardado.\n",
    "    \"\"\"\n",
    "    metric_key = metric.strip().upper()\n",
    "    if metric_key not in {\"WER\", \"CER\"}:\n",
    "        raise ValueError(\"metric debe ser 'WER' o 'CER'\")\n",
    "\n",
    "    # Orden de modelos\n",
    "    if model_order is None:\n",
    "        model_order = sorted(models_data.keys())\n",
    "\n",
    "    # Recolectar datos por modelo\n",
    "    data_by_model = []\n",
    "    labels = []\n",
    "    for m in model_order:\n",
    "        vals = []\n",
    "        for _, info in models_data.get(m, {}).items():\n",
    "            v = info.get(\"METRICS\", {}).get(metric_key, None)\n",
    "            if v is None:\n",
    "                continue\n",
    "            try:\n",
    "                v = float(v)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not (math.isnan(v) or math.isinf(v)):\n",
    "                vals.append(v)\n",
    "        if len(vals) > 0:\n",
    "            data_by_model.append(vals)\n",
    "            labels.append(m)\n",
    "\n",
    "    if not data_by_model:\n",
    "        raise ValueError(f\"No hay datos para la métrica {metric_key} en models_data.\")\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.boxplot(data_by_model, showfliers=True)\n",
    "    plt.xticks(range(1, len(labels) + 1), labels, rotation=45, ha=\"right\")\n",
    "    plt.ylabel(metric_key)\n",
    "    plt.title(f\"{metric_key} por modelo (boxplot)\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar y opcionalmente mostrar\n",
    "    if save_path is None:\n",
    "        save_path = f\"boxplot_{metric_key.lower()}.png\"\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e715d",
   "metadata": {},
   "source": [
    "Llevar todo a un excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40ff96e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_excel(models_data, path=\"resultados.xlsx\"):\n",
    "    \"\"\"\n",
    "    Exporta a un Excel con columnas: audio, REF, HYP\n",
    "    \"\"\"\n",
    "    filas = []\n",
    "    for modelo, audio in models_data.items():\n",
    "        for audio_key, info in audio.items():\n",
    "            filas.append({\n",
    "                \"modelo\": modelo,\n",
    "                \"audio\": audio_key,\n",
    "                \"REF\": tr(info.get(\"REF\", \"\")),\n",
    "                \"HYP\": tr(info.get(\"HYP\", \"\"))\n",
    "            })\n",
    "    df = pd.DataFrame(filas)\n",
    "    df.to_excel(path, index=False)\n",
    "    print(f\"Archivo Excel guardado en {path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0110e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELO:  tiny\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m models_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_adultos.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtiny\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_adultos.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m, models_data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28meval\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_adultos.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m, models_data)\n",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m, in \u001b[0;36meval\u001b[0;34m(data_archivo, modelo, models_data)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modelo \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m models_data:\n\u001b[1;32m      5\u001b[0m     models_data[modelo] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_archivo, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     r \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(f, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/whisper/__init__.py:159\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    156\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_alignment_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43malignment_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/whisper/model.py:282\u001b[0m, in \u001b[0;36mWhisper.set_alignment_heads\u001b[0;34m(self, dump)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mset_alignment_heads\u001b[39m(\u001b[38;5;28mself\u001b[39m, dump: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    279\u001b[0m     array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(\n\u001b[1;32m    280\u001b[0m         gzip\u001b[38;5;241m.\u001b[39mdecompress(base64\u001b[38;5;241m.\u001b[39mb85decode(dump)), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m    281\u001b[0m     )\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 282\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_text_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mn_text_head\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malignment_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m, mask\u001b[38;5;241m.\u001b[39mto_sparse(), persistent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "models_data = dict()\n",
    "eval(\"data_adultos.csv\",\"tiny\", models_data)\n",
    "eval(\"data_adultos.csv\",\"base\", models_data)\n",
    "eval(\"data_adultos.csv\",\"small\", models_data)\n",
    "eval(\"data_adultos.csv\",\"medium\", models_data)\n",
    "eval(\"data_adultos.csv\",\"large\", models_data)\n",
    "eval(\"data_adultos.csv\",\"turbo\", models_data)\n",
    "\n",
    "printear_models_data(models_data)\n",
    "\n",
    "WER_promedio, CER_promedio = metricas_promedio(models_data) #WER_promedio es un diccionario donde guardamos para cada modelo, su WER_promedio, idem para CER_promedio\n",
    "    \n",
    "print(\"\\nWER PROMEDIO PARA CADA MODELO:\")\n",
    "print(WER_promedio)\n",
    "print(\"\\nCER PROMEDIO PARA CADA MODELO:\")\n",
    "print(CER_promedio)\n",
    "\n",
    "paths = plot_incremental(\n",
    "    \"WER\",\n",
    "    models_data,\n",
    "    model_order=[\"tiny\",\"base\",\"small\",\"medium\",\"large\",\"turbo\"],\n",
    "    sort_audios=\"first_model\"\n",
    ")\n",
    "\n",
    "paths = plot_incremental(\n",
    "    \"CER\",\n",
    "    models_data,\n",
    "    model_order=[\"tiny\",\"base\",\"small\",\"medium\",\"large\",\"turbo\"],\n",
    "    sort_audios=\"first_model\"\n",
    ")\n",
    "print(\"Gráficos guardados en:\")\n",
    "for p in paths:\n",
    "    print(\"   \", p)\n",
    "\n",
    "orden = [\"tiny\",\"base\",\"small\",\"medium\",\"large\",\"turbo\"]  # ajustá según tus modelos\n",
    "png_wer = plot_boxplots_metric(models_data, \"WER\", model_order=orden, figsize=(12,5))\n",
    "png_cer = plot_boxplots_metric(models_data, \"CER\", model_order=orden, figsize=(12,5))\n",
    "\n",
    "print(\"Guardados en:\", png_wer, \"y\", png_cer)\n",
    "\n",
    "exportar_excel(models_data, \"transcripciones.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tiempo_de_Vida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
