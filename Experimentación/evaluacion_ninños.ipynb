{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/jr/pjt6l_vd74s5ndrpf2qthqlr0000gn/T/ipykernel_6400/290103394.py\", line 1, in <module>\n",
      "    import numpy, whisper, torch\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/whisper/__init__.py\", line 8, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/Tiempo_de_Vida/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy, whisper, torch\n",
    "from pathlib import Path\n",
    "import jiwer\n",
    "from jiwer import *\n",
    "import csv\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import wave\n",
    "import re\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e8a21",
   "metadata": {},
   "source": [
    "## Normalizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60595b90",
   "metadata": {},
   "source": [
    "Como explicamos, evaluaremos las transcripciones \"Crudas\" (sin ninguna transformación) y \"Normalizadas\" (Sin puntuaciones ni mayusculas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb7396",
   "metadata": {},
   "source": [
    "#### Transformaciones para transcripciones normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90520d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformaciones para Palabras\n",
    "tr_w = jiwer.Compose([\n",
    "    Strip(), #quitamos espacios al comienzo y al final\n",
    "    ToLowerCase(), #pasamos todo a minúsculas   \n",
    "    RemovePunctuation(), #borramos comas, puntos y signos              \n",
    "    RemoveWhiteSpace(replace_by_space=True), #limpiamos espacios extra\n",
    "    RemoveMultipleSpaces(), #idem\n",
    "    ReduceToListOfListOfWords(), #convertimos las frases en listas de listas de palabras (para contar errores por palabra)\n",
    "])\n",
    "\n",
    "#Transformaciones para Caracteres\n",
    "tr_c = jiwer.Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),\n",
    "    RemovePunctuation(),\n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "    ReduceToListOfListOfChars(), #lo llevamos a listas de caracteres en lugar de palabras\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0af80",
   "metadata": {},
   "source": [
    "#### Transformaciones para transcripciones crudas:\n",
    "Se aplican solo durante el cálculo del WER y CER de los fragmentos de los audios. Aquí se eliminan comas y signos de pregunta debido a que las referencias de estos fragmentos no contaban con las primeras y además los signos de interrogación eran usados además para marcar palabras inentendibles al momento de la escucha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f160baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para hipotesis de los audios fragmentados - Palabras - \n",
    "tr_w_crudo_sin_preguntas = Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),\n",
    "    SubstituteRegexes({\n",
    "        r\",\": \" \",       # elimina las comas\n",
    "        r\"\\?\": \" \",      # elimina los signos de pregunta\n",
    "    }),\n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "    ReduceToListOfListOfWords(),\n",
    "])\n",
    "\n",
    "#Para hipotesis de los audios fragmentados - Caracteres - \n",
    "tr_c_crudo_sin_preguntas = Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),\n",
    "    SubstituteRegexes({\n",
    "        r\",\": \" \",       # elimina las comas\n",
    "        r\"\\?\": \" \",      # elimina los signos de pregunta\n",
    "    }),\n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "    ReduceToListOfListOfChars(),\n",
    "])\n",
    "\n",
    "\n",
    "#Para referencias de los audios fragmentados - Palabras - \n",
    "tr_w_crudoREF_sin_preguntas = Compose([\n",
    "    SubstituteRegexes({\n",
    "        r\"\\?\": \" \",      # elimina los signos de pregunta\n",
    "    }),\n",
    "    ReduceToListOfListOfWords(),\n",
    "])\n",
    "\n",
    "#Para referencias de los audios fragmentados - Palabras - \n",
    "tr_c_crudoREF_sin_preguntas = Compose([\n",
    "    SubstituteRegexes({\n",
    "        r\"\\?\": \" \",      # elimina los signos de pregunta\n",
    "    }),\n",
    "    ReduceToListOfListOfChars(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc691d1",
   "metadata": {},
   "source": [
    "Estas transformaciones restantes son utilizadas para visualizar de mejor manera los resultados al momento de imprimir las transcripciones. Son identicas a las anteriores salvo que no convierten los textos a listas de palabras o caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11142ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizado:\n",
    "tr= jiwer.Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),          \n",
    "    RemovePunctuation(),               \n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "])\n",
    "\n",
    "#Crudo:\n",
    "#PARA HIPÓTESIS:\n",
    "tr_crudo_sin_preguntas = Compose([\n",
    "    Strip(),\n",
    "    ToLowerCase(),\n",
    "    SubstituteRegexes({\n",
    "        r\",\": \" \",\n",
    "        r\"\\?\": \" \",      # elimina los signos de pregunta\n",
    "    }),\n",
    "    RemoveWhiteSpace(replace_by_space=True),\n",
    "    RemoveMultipleSpaces(),\n",
    "])\n",
    "\n",
    "#PARA REFERENCIA:\n",
    "tr_crudoREF_sin_preguntas = Compose([\n",
    "    SubstituteRegexes({\n",
    "        r\"\\?\": \" \",      # elimina los signos de pregunta\n",
    "    }),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e54f5",
   "metadata": {},
   "source": [
    "#### Cálculo de métricas:\n",
    "\n",
    "Dada una referencia (transcripción a mano del audio) y una hipótesis (output transcripto por el modelo), devuelve un diccionario de métricas asociadas a ese audio y transcripción. \n",
    "Las funciones son diferentes si se trata de transcripciones crudas, normalizadas y además si son fragmentos. Esto se debe a la necesidad de utilizar diferentes transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05506241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(refs:str, hyps: str):\n",
    "    metricas = dict()\n",
    "\n",
    "    # Word Error Rate\n",
    "    out_wer = jiwer.process_words(refs, hyps, reference_transform=tr_w, hypothesis_transform=tr_w)\n",
    "    # Character Error Rate\n",
    "    out_cer = jiwer.process_characters(refs, hyps, reference_transform=tr_c, hypothesis_transform=tr_c)\n",
    "\n",
    "    metricas[\"WER\"] = out_wer.wer\n",
    "    metricas[\"CER\"] = out_cer.cer\n",
    "    metricas[\"INFO_ALINEACION\"] = jiwer.visualize_alignment(out_wer) #genera una representación del texto de cómo se alinean las palabras del REF con el HYP y se agregan marcas S, I, D. Además, un resumen con número de oraciones, s,i,d, y métricas derivadas: mer, wil, wip, wer\n",
    "    metricas[\"INFO_ERRORES\"] = jiwer.visualize_error_counts(out_wer) #genera un desglose de los errores concretos palabra por palabra (te indica todas las sustituciones, inserciones y borrados)\n",
    "    metricas[\"TIPOS DE ERRORES\"] = dict()\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"] = out_wer.substitutions\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"INSERCIONES\"] = out_wer.insertions\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"BORRADOS\"] = out_wer.deletions\n",
    "  \n",
    "    return metricas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77203386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas_crudo(refs:str, hyps: str):\n",
    "    #DADA UNA REFERENCIA (transcripción real) Y UNA HIPÓTESIS (output transcripto por el modelo) para un cierto MODELO, devuelve un diccionario de métricas asociadas a ese audio y transcripción\n",
    "    #CONSERVAMOS SIGNOS DE PREGUNTA (PARA LOS ORIGINALES)\n",
    "    metricas = dict()\n",
    "\n",
    "    # Word Error Rate\n",
    "    out_wer = jiwer.process_words(refs, hyps)\n",
    "    # Character Error Rate\n",
    "    out_cer = jiwer.process_characters(refs, hyps)\n",
    "\n",
    "    metricas[\"WER\"] = out_wer.wer\n",
    "    metricas[\"CER\"] = out_cer.cer\n",
    "    metricas[\"INFO_ALINEACION\"] = jiwer.visualize_alignment(out_wer) #genera una representación del texto de cómo se alinean las palabras del REF con el HYP y se agregan marcas S, I, D. Además, un resumen con número de oraciones, s,i,d, y métricas derivadas: mer, wil, wip, wer\n",
    "    metricas[\"INFO_ERRORES\"] = jiwer.visualize_error_counts(out_wer) #genera un desglose de los errores concretos palabra por palabra (te indica todas las sustituciones, inserciones y borrados)\n",
    "    metricas[\"TIPOS DE ERRORES\"] = dict()\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"] = out_wer.substitutions\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"INSERCIONES\"] = out_wer.insertions\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"BORRADOS\"] = out_wer.deletions\n",
    "  \n",
    "    return metricas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calcular_metricas_crudo_FRAGMENTOS(refs:str, hyps: str):\n",
    "    #DADA UNA REFERENCIA (transcripción real) Y UNA HIPÓTESIS (output transcripto por el modelo) para un cierto MODELO, devuelve un diccionario de métricas asociadas a ese audio y transcripción\n",
    "    #QUITAMOS SIGNOS DE PREGUNTA (PARA LOS FRAGMENTOS)\n",
    "    metricas = dict()\n",
    "\n",
    "    # Word Error Rate\n",
    "    out_wer = jiwer.process_words(refs, hyps, reference_transform=tr_w_crudoREF_sin_preguntas, hypothesis_transform=tr_w_crudo_sin_preguntas)\n",
    "    # Character Error Rate\n",
    "    out_cer = jiwer.process_characters(refs, hyps, reference_transform=tr_c_crudoREF_sin_preguntas, hypothesis_transform=tr_c_crudo_sin_preguntas)\n",
    "\n",
    "    metricas[\"WER\"] = out_wer.wer\n",
    "    metricas[\"CER\"] = out_cer.cer\n",
    "    metricas[\"INFO_ALINEACION\"] = jiwer.visualize_alignment(out_wer) #genera una representación del texto de cómo se alinean las palabras del REF con el HYP y se agregan marcas S, I, D. Además, un resumen con número de oraciones, s,i,d, y métricas derivadas: mer, wil, wip, wer\n",
    "    metricas[\"INFO_ERRORES\"] = jiwer.visualize_error_counts(out_wer) #genera un desglose de los errores concretos palabra por palabra (te indica todas las sustituciones, inserciones y borrados)\n",
    "    metricas[\"TIPOS DE ERRORES\"] = dict()\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"] = out_wer.substitutions\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"INSERCIONES\"] = out_wer.insertions\n",
    "    metricas[\"TIPOS DE ERRORES\"][\"BORRADOS\"] = out_wer.deletions\n",
    "  \n",
    "    return metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40415ecb",
   "metadata": {},
   "source": [
    "#### Promedio de las métricas:\n",
    "Se calcula el promedio de las metricas para cada tarea diferente. Se basa en un diccionario que contiene todas las transcripciones para las 3 tareas. Será generado más adelante en el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas_promedio(models_data:dict[dict[str:str]]):\n",
    "    promediosWER = dict()\n",
    "    promediosCER = dict()\n",
    "    \n",
    "    sumaWER_TAREA1 = 0\n",
    "    sumaCER_TAREA1 = 0\n",
    "    sumaWER_TAREA2 = 0\n",
    "    sumaCER_TAREA2 = 0\n",
    "    sumaWER_TAREA3 = 0\n",
    "    sumaCER_TAREA3 = 0\n",
    "\n",
    "    count_tarea1 = 0\n",
    "    count_tarea2 = 0\n",
    "    count_tarea3 = 0\n",
    "\n",
    "    for registro in models_data.keys(): #Recorrer por audios\n",
    "            for clave in models_data[registro].keys(): #3 ITERACIONES: TAREAS 1, 2 Y 3\n",
    "                  for fragmento in models_data[registro][clave].keys(): #Si la tarea es la 1 -> una única iteración (el audio completo), si la tarea es la 3, recorre todos los fragmentos del registro correspondiente\n",
    "                        if clave == \"TAREA 1\": \n",
    "                              sumaWER_TAREA1 += models_data[registro][clave][fragmento][\"METRICS\"][\"WER\"]\n",
    "                              sumaCER_TAREA1 += models_data[registro][clave][fragmento][\"METRICS\"][\"CER\"]\n",
    "                              count_tarea1 += 1\n",
    "                        elif clave == \"TAREA 2\":\n",
    "                              sumaWER_TAREA2 += models_data[registro][clave][fragmento][\"METRICS\"][\"WER\"]\n",
    "                              sumaCER_TAREA2 += models_data[registro][clave][fragmento][\"METRICS\"][\"CER\"]\n",
    "                              count_tarea2 += 1\n",
    "                        elif clave == \"TAREA 3\":\n",
    "                              sumaWER_TAREA3 += models_data[registro][clave][fragmento][\"METRICS\"][\"WER\"]\n",
    "                              sumaCER_TAREA3 += models_data[registro][clave][fragmento][\"METRICS\"][\"CER\"]\n",
    "                              count_tarea3 += 1\n",
    "\n",
    "    promedioWER_tarea1 = sumaWER_TAREA1/count_tarea1\n",
    "    promedioCER_tarea1 = sumaCER_TAREA1/count_tarea1\n",
    "    promedioWER_tarea2 = sumaWER_TAREA2/count_tarea2\n",
    "    promedioCER_tarea2 = sumaCER_TAREA2/count_tarea2\n",
    "    promedioWER_tarea3 = sumaWER_TAREA3/count_tarea3\n",
    "    promedioCER_tarea3 = sumaCER_TAREA3/count_tarea3   \n",
    "\n",
    "    promediosWER[\"TAREA 1\"] = promedioWER_tarea1\n",
    "    promediosWER[\"TAREA 2\"] = promedioWER_tarea2\n",
    "    promediosWER[\"TAREA 3\"] = promedioWER_tarea3\n",
    "\n",
    "    promediosCER[\"TAREA 1\"] = promedioCER_tarea1\n",
    "    promediosCER[\"TAREA 2\"] = promedioCER_tarea2\n",
    "    promediosCER[\"TAREA 3\"] = promedioCER_tarea3\n",
    "        \n",
    "    return promediosWER, promediosCER\n",
    "\n",
    "\n",
    "\n",
    "def metricas_promedio_crudo(models_data:dict[dict[str:str]]):\n",
    "    promediosWER = dict()\n",
    "    promediosCER = dict()\n",
    "    \n",
    "    sumaWER_TAREA1 = 0\n",
    "    sumaCER_TAREA1 = 0\n",
    "    sumaWER_TAREA2 = 0\n",
    "    sumaCER_TAREA2 = 0\n",
    "    sumaWER_TAREA3 = 0\n",
    "    sumaCER_TAREA3 = 0\n",
    "\n",
    "    count_tarea1 = 0\n",
    "    count_tarea2 = 0\n",
    "    count_tarea3 = 0\n",
    "\n",
    "    for registro in models_data.keys(): #Recorrer por audios\n",
    "            for clave in models_data[registro].keys(): #3 ITERACIONES: TAREAS 1, 2 Y 3\n",
    "                  for fragmento in models_data[registro][clave].keys(): #Si la tarea es la 1 -> una única iteración (el audio completo), si la tarea es la 3, recorre todos los fragmentos del registro correspondiente\n",
    "                        if clave == \"TAREA 1\": \n",
    "                              sumaWER_TAREA1 += models_data[registro][clave][fragmento][\"RAW METRICS\"][\"WER\"]\n",
    "                              sumaCER_TAREA1 += models_data[registro][clave][fragmento][\"RAW METRICS\"][\"CER\"]\n",
    "                              count_tarea1 += 1\n",
    "                        elif clave == \"TAREA 2\":\n",
    "                              sumaWER_TAREA2 += models_data[registro][clave][fragmento][\"RAW METRICS\"][\"WER\"]\n",
    "                              sumaCER_TAREA2 += models_data[registro][clave][fragmento][\"RAW METRICS\"][\"CER\"]\n",
    "                              count_tarea2 += 1\n",
    "                        elif clave == \"TAREA 3\":\n",
    "                              sumaWER_TAREA3 += models_data[registro][clave][fragmento][\"RAW METRICS\"][\"WER\"]\n",
    "                              sumaCER_TAREA3 += models_data[registro][clave][fragmento][\"RAW METRICS\"][\"CER\"]\n",
    "                              count_tarea3 += 1\n",
    "\n",
    "    promedioWER_tarea1 = sumaWER_TAREA1/count_tarea1\n",
    "    promedioCER_tarea1 = sumaCER_TAREA1/count_tarea1\n",
    "    promedioWER_tarea2 = sumaWER_TAREA2/count_tarea2\n",
    "    promedioCER_tarea2 = sumaCER_TAREA2/count_tarea2\n",
    "    promedioWER_tarea3 = sumaWER_TAREA3/count_tarea3\n",
    "    promedioCER_tarea3 = sumaCER_TAREA3/count_tarea3   \n",
    "\n",
    "    promediosWER[\"TAREA 1\"] = promedioWER_tarea1\n",
    "    promediosWER[\"TAREA 2\"] = promedioWER_tarea2\n",
    "    promediosWER[\"TAREA 3\"] = promedioWER_tarea3\n",
    "\n",
    "    promediosCER[\"TAREA 1\"] = promedioCER_tarea1\n",
    "    promediosCER[\"TAREA 2\"] = promedioCER_tarea2\n",
    "    promediosCER[\"TAREA 3\"] = promedioCER_tarea3\n",
    "        \n",
    "    return promediosWER, promediosCER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480941f5",
   "metadata": {},
   "source": [
    "#### Transcripción y confección del diccionario principal que almacenará todos nuestros resultados:\n",
    "A partir de un csv con la ruta a los audios y sus referencias, se realizan las correspondientes transcripciones y se almacenan en el diccionario \"results\" junto a los WER Y CER para las versiones crudas y normalizadas. \n",
    "\n",
    "El diccionario result se organizará de la siguiente manera:\n",
    "\n",
    "results[nombre del audio global][tarea 1, 2 o 3][nombre del archivo derivado][referencia, hipotesis o métricas]\n",
    "\n",
    "La diferencia entre el nombre del audio global y el nombre del archivo derivado es que el primero se comparte entre las tres tareas y el último es unico para cada fragmento, audio reconstruido y audio cpmpleto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7570f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_archivo:str, modelo:str, models_data, audio_root: str, clave: str):\n",
    "    model = whisper.load_model(modelo)\n",
    "\n",
    "    carpeta_audios = Path(audio_root)\n",
    "    print(\"LA CARPETA ES: \", carpeta_audios)\n",
    "    if not carpeta_audios.exists():\n",
    "        raise FileNotFoundError(f\"Carpeta de audios no encontrada: {audio_root}\")\n",
    "\n",
    "    with open(data_archivo, encoding=\"utf-8\") as f:\n",
    "        r = csv.DictReader(f, delimiter=\",\")\n",
    "        \n",
    "        #RECORREMOS CADA REGISTRO DEL CSV\n",
    "        for registro in r: \n",
    "            #GUARDAMOS EL AUDIO WAV Y SU REFERENCIA \n",
    "            audio = registro['AUDIO']\n",
    "            ref = registro[\"TRANSCRIPCION\"]\n",
    "            origen = registro[\"AUDIO_ORIGINAL\"]\n",
    "            audio_path = carpeta_audios / audio\n",
    "            print(\"EL PATH ES: \", audio_path)\n",
    "            #TRANSCRIBIMOS, OBTENIENDO LA HIPÓTESIS DEL MODELO\n",
    "            output = model.transcribe(str(audio_path), language=\"es\", fp16=False, temperature=0.0)\n",
    "            hyp = output[\"text\"]\n",
    "\n",
    "\n",
    "            #CALCULAMOS MÉTRICAS\n",
    "            metricas = calcular_metricas(ref, hyp)\n",
    "            if clave == \"TAREA 1\" or clave == \"TAREA 2\":\n",
    "                metricas_crudo = calcular_metricas_crudo(ref, hyp)\n",
    "            elif clave == \"TAREA 3\":\n",
    "                metricas_crudo = calcular_metricas_crudo_FRAGMENTOS(ref, hyp)\n",
    "            \n",
    "            audio_key = origen\n",
    "            print(audio_key)\n",
    "            if audio_key not in models_data.keys():\n",
    "                models_data[audio_key] = dict()\n",
    "            if clave not in models_data[audio_key].keys():\n",
    "                models_data[audio_key][clave] = dict()\n",
    "\n",
    "            audio_tarea = Path(audio).stem \n",
    "            models_data[audio_key][clave][audio_tarea] = dict()\n",
    "            \n",
    "            if clave == \"TAREA 1\" or clave == \"TAREA 2\":\n",
    "                models_data[audio_key][clave][audio_tarea][\"REF CRUDA\"] = ref\n",
    "                models_data[audio_key][clave][audio_tarea][\"HYP CRUDA\"] = hyp\n",
    "            elif clave == \"TAREA 3\": \n",
    "                models_data[audio_key][clave][audio_tarea][\"REF CRUDA\"] = tr_crudoREF_sin_preguntas(ref) #solo sacamos signos de pregunta\n",
    "                models_data[audio_key][clave][audio_tarea][\"HYP CRUDA\"] = tr_crudo_sin_preguntas(hyp) #sacamos signos de pregunta + trasformaciones que quitan comas y mayúsculas\n",
    "\n",
    "\n",
    "            models_data[audio_key][clave][audio_tarea][\"REF\"] = tr(ref)\n",
    "            models_data[audio_key][clave][audio_tarea][\"HYP\"] = tr(hyp)\n",
    "            models_data[audio_key][clave][audio_tarea][\"OUTPUT TOTAL\"] = output\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"] = dict()\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"WER\"] = metricas[\"WER\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"CER\"] = metricas[\"CER\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"INFO_ALINEACION\"] = metricas[\"INFO_ALINEACION\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"INFO_ERRORES\"] = metricas[\"INFO_ERRORES\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"TIPOS DE ERRORES\"] = dict()\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"] = metricas[\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"TIPOS DE ERRORES\"][\"INSERCIONES\"] = metricas[\"TIPOS DE ERRORES\"][\"INSERCIONES\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"METRICS\"][\"TIPOS DE ERRORES\"][\"BORRADOS\"] = metricas[\"TIPOS DE ERRORES\"][\"BORRADOS\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"] = dict()\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"WER\"] = metricas_crudo[\"WER\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"CER\"] = metricas_crudo[\"CER\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"INFO_ALINEACION\"] = metricas_crudo[\"INFO_ALINEACION\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"INFO_ERRORES\"] = metricas_crudo[\"INFO_ERRORES\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"TIPOS DE ERRORES\"] = dict()\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"] = metricas_crudo[\"TIPOS DE ERRORES\"][\"SUSTITUCIONES\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"TIPOS DE ERRORES\"][\"INSERCIONES\"] = metricas_crudo[\"TIPOS DE ERRORES\"][\"INSERCIONES\"]\n",
    "            models_data[audio_key][clave][audio_tarea][\"RAW METRICS\"][\"TIPOS DE ERRORES\"][\"BORRADOS\"] = metricas_crudo[\"TIPOS DE ERRORES\"][\"BORRADOS\"]\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf71da",
   "metadata": {},
   "source": [
    "#### Imprimir de una forma amigable el diccionario results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printear_models_data(models_data: dict):\n",
    "    print(\"\\n================= RESULTADOS =================\\n\")\n",
    "    \n",
    "    for audio_key, tareas in models_data.items():\n",
    "        print(f\"AUDIO ORIGINAL: {audio_key}\\n\")\n",
    "        \n",
    "        for clave_tarea, fragmentos in tareas.items():\n",
    "            print(f\"  >> {clave_tarea}\")\n",
    "            \n",
    "            for audio_tarea, info in fragmentos.items():\n",
    "                print(f\"\\n    FRAGMENTO: {audio_tarea}\")\n",
    "\n",
    "                print(f\"        OUTPUT TOTAL: {info['OUTPUT TOTAL']}\\n\")\n",
    "\n",
    "\n",
    "                print(f\"        REF: {info['REF']}\")\n",
    "                print(f\"        HYP: {info['HYP']}\\n\")\n",
    "                \n",
    "                # --- Métricas procesadas ---\n",
    "                m = info[\"METRICS\"]\n",
    "                print(\"        MÉTRICAS PROCESADAS:\")\n",
    "                print(f\"            - WER: {m['WER']:.3f}\")\n",
    "                print(f\"            - CER: {m['CER']:.3f}\")\n",
    "                print(\"            - ALINEACIÓN (palabras):\")\n",
    "                print(f\"                  {m['INFO_ALINEACION']}\")\n",
    "                print(\"            - ERRORES (resumen):\")\n",
    "                print(f\"                  {m['INFO_ERRORES']}\")\n",
    "                print(\"            - TIPOS DE ERRORES:\")\n",
    "                print(f\"                  Sustituciones: {m['TIPOS DE ERRORES']['SUSTITUCIONES']}\")\n",
    "                print(f\"                  Inserciones:   {m['TIPOS DE ERRORES']['INSERCIONES']}\")\n",
    "                print(f\"                  Borrados:      {m['TIPOS DE ERRORES']['BORRADOS']}\")\n",
    "                print()\n",
    "                \n",
    "                \n",
    "                print(f\"        REF cruda: {info['REF CRUDA']}\")\n",
    "                print(f\"        HYP cruda: {info['HYP CRUDA']}\\n\")\n",
    "                # --- Métricas crudas ---\n",
    "                n = info[\"RAW METRICS\"]\n",
    "                print(\"        MÉTRICAS CRUDAS:\")\n",
    "                print(f\"            - WER: {n['WER']:.3f}\")\n",
    "                print(f\"            - CER: {n['CER']:.3f}\")\n",
    "                print(\"            - ALINEACIÓN (palabras):\")\n",
    "                print(f\"                  {n['INFO_ALINEACION']}\")\n",
    "                print(\"            - ERRORES (resumen):\")\n",
    "                print(f\"                  {n['INFO_ERRORES']}\")\n",
    "                print(\"            - TIPOS DE ERRORES:\")\n",
    "                print(f\"                  Sustituciones: {n['TIPOS DE ERRORES']['SUSTITUCIONES']}\")\n",
    "                print(f\"                  Inserciones:   {n['TIPOS DE ERRORES']['INSERCIONES']}\")\n",
    "                print(f\"                  Borrados:      {n['TIPOS DE ERRORES']['BORRADOS']}\")\n",
    "                print(\"\\n--------------------------------------------------\\n\")\n",
    "        print(\"==================================================\\n\")\n",
    "    \n",
    "    print(\"================= FIN RESULTADOS =================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18228276",
   "metadata": {},
   "source": [
    "#### Código de evaluación principa\n",
    "\n",
    "Tomando el modelo Turbo, el cual es alterable, ejecutamos las 3 tareas para el total de los audios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\"turbo\"]\n",
    "niños_data = dict()\n",
    "\n",
    "\n",
    "for modelo in modelos: \n",
    "    #Tarea 1: TRANSCRIPCIÓN DEL AUDIO ORIGINAL \n",
    "    archivo = \"docs_niños/completos.csv\"\n",
    "    audio_root = \"audios_niños/Audios completos\"\n",
    "    clave = \"TAREA 1\"\n",
    "    eval(archivo, modelo, niños_data, audio_root, clave)\n",
    "\n",
    "    #Tarea 2: TRANSCRIPCIÓN DEL AUDIO CONCATENADO\n",
    "    archivo = \"docs_niños/reconstruidos.csv\"\n",
    "    audio_root = \"audios_niños/Audios reconstruidos\"\n",
    "    clave = \"TAREA 2\"\n",
    "    eval(archivo, modelo, niños_data, audio_root, clave) \n",
    "\n",
    "\n",
    "    #Tarea 3: TRANSCRIPCIÓN DE FRAGMENTOS \n",
    "    archivo = \"docs_niños/fragmentos.csv\"\n",
    "    audio_root = \"audios_niños/Audios fragmentados\"\n",
    "    clave = \"TAREA 3\"\n",
    "    eval(archivo, modelo, niños_data, audio_root, clave)\n",
    "    print(\"TAREA 3 FINALIZADA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf565ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "printear_models_data(niños_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3776f87",
   "metadata": {},
   "source": [
    "Con los resultados en nuestras manos, calculamos el WER y el CER promedio para cada tarea tanto para las versiones crudas como normalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063379f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WERs_promedios, CERs_promedios = metricas_promedio(niños_data)\n",
    "print(\"\\nWER PROMEDIO DE TAREA 1:\")\n",
    "print(WERs_promedios[\"TAREA 1\"])\n",
    "print(\"\\nCER PROMEDIO DE TAREA 1:\")\n",
    "print(CERs_promedios[\"TAREA 1\"])\n",
    "\n",
    "print(\"\\nWER PROMEDIO DE TAREA 2:\")\n",
    "print(WERs_promedios[\"TAREA 2\"])\n",
    "print(\"\\nCER PROMEDIO DE TAREA 2:\")\n",
    "print(CERs_promedios[\"TAREA 2\"])\n",
    "\n",
    "print(\"\\nWER PROMEDIO DE TAREA 3:\")\n",
    "print(WERs_promedios[\"TAREA 3\"])\n",
    "print(\"\\nCER PROMEDIO DE TAREA 3:\")\n",
    "print(CERs_promedios[\"TAREA 3\"])\n",
    "\n",
    "WERs_promedios_crudo, CERs_promedios_crudo = metricas_promedio_crudo(niños_data)\n",
    "    \n",
    "print(\"\\nWER PROMEDIO DE TAREA 1 CRUDO:\")\n",
    "print(WERs_promedios_crudo[\"TAREA 1\"])\n",
    "print(\"\\nCER PROMEDIO DE TAREA 1 CRUDO:\")\n",
    "print(CERs_promedios_crudo[\"TAREA 1\"])\n",
    "\n",
    "print(\"\\nWER PROMEDIO DE TAREA 2 CRUDO:\")\n",
    "print(WERs_promedios_crudo[\"TAREA 2\"])\n",
    "print(\"\\nCER PROMEDIO DE TAREA 2 CRUDO:\")\n",
    "print(CERs_promedios_crudo[\"TAREA 2\"])\n",
    "\n",
    "print(\"\\nWER PROMEDIO DE TAREA 3 CRUDO:\")\n",
    "print(WERs_promedios_crudo[\"TAREA 3\"])\n",
    "print(\"\\nCER PROMEDIO DE TAREA 3 CRUDO:\")\n",
    "print(CERs_promedios_crudo[\"TAREA 3\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40315b45",
   "metadata": {},
   "source": [
    "Guardar en un archivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f378c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tarea_num(clave_tarea: str) -> int:\n",
    "    m = re.search(r\"(\\d+)\", str(clave_tarea))\n",
    "    return int(m.group(1)) if m else 999\n",
    "\n",
    "def _natural_key(s: str):\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r\"(\\d+)\", str(s))]\n",
    "\n",
    "def _safe_get(d, *keys, default=\"\"):\n",
    "    cur = d\n",
    "    for k in keys:\n",
    "        if not isinstance(cur, dict) or k not in cur:\n",
    "            return default\n",
    "        cur = cur[k]\n",
    "    return cur\n",
    "\n",
    "def exportar_excel_asr(models_data: dict, path=\"resultados.xlsx\"):\n",
    "    \"\"\"\n",
    "    Genera un Excel con filas en orden:\n",
    "      AUDIO, TAREA 1, TAREA 2, TAREA 3 (un renglón por fragmento).\n",
    "    Columnas:\n",
    "      AUDIO, TAREA, FRAGMENTO,\n",
    "      REF CRUDA, HYP CRUDA, REF, HYP,\n",
    "      WER, CER, SUSTITUCIONES, INSERCIONES, BORRADOS,\n",
    "      WER crudo, CER crudo, SUSTITUCIONES crudo, INSERCIONES crudo, BORRADOS crudo\n",
    "    \"\"\"\n",
    "    filas = []\n",
    "\n",
    "    for audio_key in sorted(models_data.keys()):\n",
    "        tareas = models_data[audio_key]\n",
    "\n",
    "        for tn in [1, 2, 3]:\n",
    "            # buscar la clave 'TAREA X'\n",
    "            clave_tarea = None\n",
    "            for k in tareas.keys():\n",
    "                if _tarea_num(k) == tn:\n",
    "                    clave_tarea = k\n",
    "                    break\n",
    "            if clave_tarea is None:\n",
    "                continue\n",
    "\n",
    "            fragmentos = tareas[clave_tarea]\n",
    "            for frag in sorted(fragmentos.keys(), key=_natural_key):\n",
    "                info = fragmentos[frag]\n",
    "\n",
    "                # Textos crudos y transformados\n",
    "                ref_cruda = _safe_get(info, \"REF CRUDA\", default=\"\")\n",
    "                hyp_cruda = _safe_get(info, \"HYP CRUDA\", default=\"\")\n",
    "                ref_txt   = _safe_get(info, \"REF\", default=\"\")\n",
    "                hyp_txt   = _safe_get(info, \"HYP\", default=\"\")\n",
    "\n",
    "                # Métricas procesadas\n",
    "                m = _safe_get(info, \"METRICS\", default={})\n",
    "                mt = _safe_get(m, \"TIPOS DE ERRORES\", default={})\n",
    "\n",
    "                # Métricas crudas\n",
    "                n = _safe_get(info, \"RAW METRICS\", default={})\n",
    "                nt = _safe_get(n, \"TIPOS DE ERRORES\", default={})\n",
    "\n",
    "                filas.append({\n",
    "                    \"AUDIO\": audio_key,\n",
    "                    \"TAREA\": tn,\n",
    "                    \"FRAGMENTO\": frag if tn == 3 else \"\",\n",
    "\n",
    "                    \"REF CRUDA\": ref_cruda,\n",
    "                    \"HYP CRUDA\": hyp_cruda,\n",
    "                    \"REF\": ref_txt,\n",
    "                    \"HYP\": hyp_txt,\n",
    "\n",
    "                    # Procesadas\n",
    "                    \"WER\": _safe_get(m, \"WER\", default=\"\"),\n",
    "                    \"CER\": _safe_get(m, \"CER\", default=\"\"),\n",
    "                    \"SUSTITUCIONES\": _safe_get(mt, \"SUSTITUCIONES\", default=0),\n",
    "                    \"INSERCIONES\":  _safe_get(mt, \"INSERCIONES\",  default=0),\n",
    "                    \"BORRADOS\":     _safe_get(mt, \"BORRADOS\",     default=0),\n",
    "\n",
    "                    # Crudas\n",
    "                    \"WER crudo\": _safe_get(n, \"WER\", default=\"\"),\n",
    "                    \"CER crudo\": _safe_get(n, \"CER\", default=\"\"),\n",
    "                    \"SUSTITUCIONES crudo\": _safe_get(nt, \"SUSTITUCIONES\", default=0),\n",
    "                    \"INSERCIONES crudo\":  _safe_get(nt, \"INSERCIONES\",  default=0),\n",
    "                    \"BORRADOS crudo\":     _safe_get(nt, \"BORRADOS\",     default=0),\n",
    "                })\n",
    "\n",
    "    cols = [\n",
    "        \"AUDIO\", \"TAREA\", \"FRAGMENTO\",\n",
    "        \"REF CRUDA\", \"HYP CRUDA\", \"REF\", \"HYP\",\n",
    "        \"WER\", \"CER\", \"SUSTITUCIONES\", \"INSERCIONES\", \"BORRADOS\",\n",
    "        \"WER crudo\", \"CER crudo\", \"SUSTITUCIONES crudo\", \"INSERCIONES crudo\", \"BORRADOS crudo\",\n",
    "    ]\n",
    "    df = pd.DataFrame(filas, columns=cols)\n",
    "\n",
    "    # ---- Exportar con formato (XlsxWriter) ----\n",
    "    with pd.ExcelWriter(path, engine=\"xlsxwriter\") as writer:\n",
    "        sheet = \"ASR\"\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet)\n",
    "\n",
    "        wb = writer.book\n",
    "        ws = writer.sheets[sheet]\n",
    "\n",
    "        wrap_fmt   = wb.add_format({\"text_wrap\": True, \"valign\": \"top\"})\n",
    "        normal_fmt = wb.add_format({\"valign\": \"vcenter\"})\n",
    "        num_fmt4   = wb.add_format({\"valign\": \"vcenter\", \"num_format\": \"0.0000\"})\n",
    "\n",
    "        max_width_cap = 80\n",
    "        min_width_text = 12\n",
    "        numeric_cols = {\"WER\", \"CER\", \"WER crudo\", \"CER crudo\"}\n",
    "\n",
    "        for col_idx, col_name in enumerate(df.columns):\n",
    "            series = df[col_name].astype(str) if not df.empty else pd.Series([col_name])\n",
    "            max_len = max([len(col_name)] + [len(s) for s in series])\n",
    "\n",
    "            if col_name in (\"REF CRUDA\", \"HYP CRUDA\", \"REF\", \"HYP\"):\n",
    "                width = min(max(max_len, 40), max_width_cap)\n",
    "                ws.set_column(col_idx, col_idx, width, wrap_fmt)\n",
    "            elif col_name in numeric_cols:\n",
    "                ws.set_column(col_idx, col_idx, 12, num_fmt4)\n",
    "            else:\n",
    "                width = min(max(max_len + 2, min_width_text), 28)\n",
    "                ws.set_column(col_idx, col_idx, width, normal_fmt)\n",
    "\n",
    "        # Alto de fila según REF/HYP (transformadas) para que se vean completas\n",
    "        base_height = 15\n",
    "        char_per_line = 80\n",
    "        for row_idx in range(len(df)):\n",
    "            lines_needed = 1\n",
    "            for col in (\"REF\", \"HYP\"):\n",
    "                text = str(df.at[row_idx, col]).strip()\n",
    "                if text:\n",
    "                    logical_lines = text.count(\"\\n\") + 1\n",
    "                    wrapped_lines = math.ceil(len(text) / char_per_line)\n",
    "                    lines_needed = max(lines_needed, logical_lines, wrapped_lines)\n",
    "            ws.set_row(row_idx + 1, base_height * lines_needed, wrap_fmt)\n",
    "\n",
    "    print(f\"Archivo guardado en {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f58e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportar_excel_asr(niños_data, path=\"resultados_experimentacion_niños.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tiempo_de_Vida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
